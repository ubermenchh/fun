{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"***This notebook is my way through the HuggingFace Diffusers Course***","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Introduction to Diffusers","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Setup","metadata":{}},{"cell_type":"code","source":"%pip install -qq -U diffusers datasets transformers accelerate ftfy pyarrow==9.0.0","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:53:20.138035Z","iopub.execute_input":"2023-11-01T12:53:20.138731Z","iopub.status.idle":"2023-11-01T12:53:55.822678Z","shell.execute_reply.started":"2023-11-01T12:53:20.138693Z","shell.execute_reply":"2023-11-01T12:53:55.821522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:53:55.824497Z","iopub.execute_input":"2023-11-01T12:53:55.824834Z","iopub.status.idle":"2023-11-01T12:53:56.108665Z","shell.execute_reply.started":"2023-11-01T12:53:55.824804Z","shell.execute_reply":"2023-11-01T12:53:56.107774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!sudo apt -qq install git-lfs\n!git config --global credential.helper store","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:55:01.684815Z","iopub.execute_input":"2023-11-01T12:55:01.685173Z","iopub.status.idle":"2023-11-01T12:55:05.561775Z","shell.execute_reply.started":"2023-11-01T12:55:01.685142Z","shell.execute_reply":"2023-11-01T12:55:05.560405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:55:20.568043Z","iopub.execute_input":"2023-11-01T12:55:20.568444Z","iopub.status.idle":"2023-11-01T12:55:23.429117Z","shell.execute_reply.started":"2023-11-01T12:55:20.568408Z","shell.execute_reply":"2023-11-01T12:55:23.428241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(x):\n    x = x * 0.5 + 0.5\n    grid = torchvision.utils.make_grid(x)\n    grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255\n    grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))\n    return grid_im\n\ndef make_grid(images, size=64):\n    output_im = Image.new('RGB', (size * len(images), size))\n    for i, im in enumerate(images):\n        output_im.paste(im.resize((size, size)), (i * size, 0))\n    return output_im","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:55:23.430710Z","iopub.execute_input":"2023-11-01T12:55:23.431086Z","iopub.status.idle":"2023-11-01T12:55:23.438219Z","shell.execute_reply.started":"2023-11-01T12:55:23.431060Z","shell.execute_reply":"2023-11-01T12:55:23.437291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:55:23.439272Z","iopub.execute_input":"2023-11-01T12:55:23.439578Z","iopub.status.idle":"2023-11-01T12:55:23.482262Z","shell.execute_reply.started":"2023-11-01T12:55:23.439552Z","shell.execute_reply":"2023-11-01T12:55:23.481267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline\n\nmodel_id = \"sd-dreambooth-library/mr-potato-head\"\n\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:55:23.483936Z","iopub.execute_input":"2023-11-01T12:55:23.484269Z","iopub.status.idle":"2023-11-01T12:57:12.146597Z","shell.execute_reply.started":"2023-11-01T12:55:23.484242Z","shell.execute_reply":"2023-11-01T12:57:12.145522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = 'an abstract oil painting of a white labrador puppy by van gogh'\nimage = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\nimage","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:57:12.148394Z","iopub.execute_input":"2023-11-01T12:57:12.149015Z","iopub.status.idle":"2023-11-01T12:57:30.218488Z","shell.execute_reply.started":"2023-11-01T12:57:12.148985Z","shell.execute_reply":"2023-11-01T12:57:30.217566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Minimum Viable Pipeline (MVP)","metadata":{}},{"cell_type":"code","source":"from diffusers import DDPMPipeline\n\nbutterfly_pipeline = DDPMPipeline.from_pretrained(\"johnowhitaker/ddpm-butterflies-32px\").to(device)\nimages = butterfly_pipeline(batch_size=8).images\nmake_grid(images)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:58:15.327996Z","iopub.execute_input":"2023-11-01T12:58:15.328392Z","iopub.status.idle":"2023-11-01T12:58:44.280859Z","shell.execute_reply.started":"2023-11-01T12:58:15.328351Z","shell.execute_reply":"2023-11-01T12:58:44.279942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training Process of a Diffusion Model:**\n1. Load in some images from the training data.\n2. Add noise, in different amounts.\n3. Feed the noisy versions of the inputs into the model.\n4. Evaluate how well the model does at denoising these inputs.\n5. Use this information to update the model weights, and repeat.","metadata":{}},{"cell_type":"markdown","source":"## Step 2: Download a Training Dataset","metadata":{}},{"cell_type":"code","source":"import torchvision\nfrom datasets import load_dataset\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:58:47.821465Z","iopub.execute_input":"2023-11-01T12:58:47.821822Z","iopub.status.idle":"2023-11-01T12:58:48.396624Z","shell.execute_reply.started":"2023-11-01T12:58:47.821796Z","shell.execute_reply":"2023-11-01T12:58:48.395630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"huggan/smithsonian_butterflies_subset\", split='train')\nimage_size = 32\nbatch_size = 64\n\npreprocess = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:59:10.633390Z","iopub.execute_input":"2023-11-01T12:59:10.634634Z","iopub.status.idle":"2023-11-01T12:59:29.629974Z","shell.execute_reply.started":"2023-11-01T12:59:10.634600Z","shell.execute_reply":"2023-11-01T12:59:29.629225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(examples):\n    images = [preprocess(image.convert('RGB')) for image in examples['image']]\n    return {'images': images}\n\ndataset.set_transform(transform)\n\ntrain_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:00.049138Z","iopub.execute_input":"2023-11-01T13:00:00.049868Z","iopub.status.idle":"2023-11-01T13:00:00.061157Z","shell.execute_reply.started":"2023-11-01T13:00:00.049830Z","shell.execute_reply":"2023-11-01T13:00:00.060075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb = next(iter(train_dataloader))['images'].to(device)[:8]\nprint(\"X shape: \", xb.shape)\nshow_images(xb).resize((8*64, 64), resample=Image.NEAREST)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:00.571214Z","iopub.execute_input":"2023-11-01T13:00:00.571634Z","iopub.status.idle":"2023-11-01T13:00:01.037696Z","shell.execute_reply.started":"2023-11-01T13:00:00.571583Z","shell.execute_reply":"2023-11-01T13:00:01.036790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Define the Scheduler","metadata":{}},{"cell_type":"code","source":"from diffusers import DDPMScheduler\n\nnoise_scheduler = DDPMScheduler(num_train_timesteps=1000)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:02.177180Z","iopub.execute_input":"2023-11-01T13:00:02.178049Z","iopub.status.idle":"2023-11-01T13:00:02.182844Z","shell.execute_reply.started":"2023-11-01T13:00:02.178012Z","shell.execute_reply":"2023-11-01T13:00:02.181942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(noise_scheduler.alphas_cumprod.cpu() ** 0.5, label=r\"${\\sqrt{\\bar{\\alpha}_t}}$\")\nplt.plot((1 - noise_scheduler.alphas_cumprod.cpu()) ** 0.5, label=r\"$\\sqrt{(1 - \\bar{\\alpha}_t)}$\")\nplt.legend(fontsize=\"x-large\");","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:03.271980Z","iopub.execute_input":"2023-11-01T13:00:03.272388Z","iopub.status.idle":"2023-11-01T13:00:03.756735Z","shell.execute_reply.started":"2023-11-01T13:00:03.272346Z","shell.execute_reply":"2023-11-01T13:00:03.755756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_start=0.001, beta_end=0.004)\n\nplt.plot(noise_scheduler.alphas_cumprod.cpu() ** 0.5, label=r\"${\\sqrt{\\bar{\\alpha}_t}}$\")\nplt.plot((1 - noise_scheduler.alphas_cumprod.cpu()) ** 0.5, label=r\"$\\sqrt{(1 - \\bar{\\alpha}_t)}$\")\nplt.legend(fontsize=\"x-large\");","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:03.758285Z","iopub.execute_input":"2023-11-01T13:00:03.758633Z","iopub.status.idle":"2023-11-01T13:00:04.164735Z","shell.execute_reply.started":"2023-11-01T13:00:03.758607Z","shell.execute_reply":"2023-11-01T13:00:04.163809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2')\n\nplt.plot(noise_scheduler.alphas_cumprod.cpu() ** 0.5, label=r\"${\\sqrt{\\bar{\\alpha}_t}}$\")\nplt.plot((1 - noise_scheduler.alphas_cumprod.cpu()) ** 0.5, label=r\"$\\sqrt{(1 - \\bar{\\alpha}_t)}$\")\nplt.legend(fontsize=\"x-large\");","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:04.587576Z","iopub.execute_input":"2023-11-01T13:00:04.587925Z","iopub.status.idle":"2023-11-01T13:00:04.942594Z","shell.execute_reply.started":"2023-11-01T13:00:04.587891Z","shell.execute_reply":"2023-11-01T13:00:04.941665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timesteps = torch.linspace(0, 999, 8).long().to(device)\nnoise = torch.randn_like(xb)\nnoisy_xb = noise_scheduler.add_noise(xb, noise, timesteps)\nprint(\"Noisy X Shape\", noisy_xb.shape)\nshow_images(noisy_xb).resize((8*64, 64), resample=Image.NEAREST)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:04.944657Z","iopub.execute_input":"2023-11-01T13:00:04.945091Z","iopub.status.idle":"2023-11-01T13:00:04.965621Z","shell.execute_reply.started":"2023-11-01T13:00:04.945055Z","shell.execute_reply":"2023-11-01T13:00:04.964699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Define the Model","metadata":{}},{"cell_type":"markdown","source":"### U-Net\nIn a Nutshell,\n- the model has the input image go through several blocks of ResNet layers, each of which halves the images size by 2.\n- then through the same number of blocks that upsample it again.\n- there are skip connections linking the features on the downsample path to the corresponding layers in the upsample path.","metadata":{}},{"cell_type":"code","source":"from diffusers import UNet2DModel\n\nmodel = UNet2DModel(\n    sample_size=image_size,\n    in_channels=3,\n    out_channels=3,\n    layers_per_block=2,\n    block_out_channels=(64, 128, 128, 256),\n    down_block_types=(\n        'DownBlock2D',\n        'DownBlock2D',\n        'AttnDownBlock2D',\n        'AttnDownBlock2D'\n    ),\n    up_block_types=(\n        'AttnUpBlock2D',\n        'AttnUpBlock2D',\n        'UpBlock2D',\n        'UpBlock2D'\n    )\n)\n\nmodel.to(device);","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:08.490263Z","iopub.execute_input":"2023-11-01T13:00:08.490943Z","iopub.status.idle":"2023-11-01T13:00:08.682718Z","shell.execute_reply.started":"2023-11-01T13:00:08.490908Z","shell.execute_reply":"2023-11-01T13:00:08.681835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    model_pred = model(noisy_xb, timesteps).sample\nmodel_pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:09.684879Z","iopub.execute_input":"2023-11-01T13:00:09.685755Z","iopub.status.idle":"2023-11-01T13:00:09.716848Z","shell.execute_reply.started":"2023-11-01T13:00:09.685719Z","shell.execute_reply":"2023-11-01T13:00:09.715962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Create a Training Loop","metadata":{}},{"cell_type":"code","source":"noise_scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule='squaredcos_cap_v2')\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=4e-4)\nlosses = []\n\nfor epoch in range(30):\n    for step, batch in enumerate(train_dataloader):\n        clean_images = batch['images'].to(device)\n        \n        # Sample noise to add to the images\n        noise = torch.randn(clean_images.shape).to(clean_images.device)\n        bs = clean_images.shape[0]\n        \n        # Sample a random timestep for each image\n        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device).long()\n        \n        # Add noise to the clean images according to the noise magnitude at each timestep\n        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n        \n        # Get the model prediction\n        noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n        \n        # Calculate the loss\n        loss = F.mse_loss(noise_pred, noise)\n        loss.backward(loss)\n        losses.append(loss.item())\n        \n        # Update the model parameters with the optimizer\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    if (epoch + 1) % 5 == 0:\n        loss_last_epoch = sum(losses[-len(train_dataloader):]) / len(train_dataloader)\n        print(f\"Epoch: {epoch+1}, Loss: {loss_last_epoch}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:00:11.431211Z","iopub.execute_input":"2023-11-01T13:00:11.431591Z","iopub.status.idle":"2023-11-01T13:04:39.617648Z","shell.execute_reply.started":"2023-11-01T13:00:11.431559Z","shell.execute_reply":"2023-11-01T13:04:39.616693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(12, 4))\naxs[0].plot(losses)\naxs[1].plot(np.log(losses))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:04:39.619721Z","iopub.execute_input":"2023-11-01T13:04:39.620484Z","iopub.status.idle":"2023-11-01T13:04:39.985436Z","shell.execute_reply.started":"2023-11-01T13:04:39.620445Z","shell.execute_reply":"2023-11-01T13:04:39.984419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6: Generate Images","metadata":{}},{"cell_type":"markdown","source":"### Option 1: Creating a Pipeline","metadata":{}},{"cell_type":"code","source":"from diffusers import DDPMPipeline\n\nimage_pipe = DDPMPipeline(unet=model, scheduler=noise_scheduler)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:04:39.986706Z","iopub.execute_input":"2023-11-01T13:04:39.987021Z","iopub.status.idle":"2023-11-01T13:04:39.991927Z","shell.execute_reply.started":"2023-11-01T13:04:39.986994Z","shell.execute_reply":"2023-11-01T13:04:39.991003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_output = image_pipe()\npipeline_output.images[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:04:39.993856Z","iopub.execute_input":"2023-11-01T13:04:39.994124Z","iopub.status.idle":"2023-11-01T13:05:01.217866Z","shell.execute_reply.started":"2023-11-01T13:04:39.994100Z","shell.execute_reply":"2023-11-01T13:05:01.216885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_pipe.save_pretrained('my_pipeline')","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:01.219030Z","iopub.execute_input":"2023-11-01T13:05:01.219339Z","iopub.status.idle":"2023-11-01T13:05:01.350648Z","shell.execute_reply.started":"2023-11-01T13:05:01.219291Z","shell.execute_reply":"2023-11-01T13:05:01.349865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls my_pipeline/","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:01.351754Z","iopub.execute_input":"2023-11-01T13:05:01.352091Z","iopub.status.idle":"2023-11-01T13:05:02.389808Z","shell.execute_reply.started":"2023-11-01T13:05:01.352057Z","shell.execute_reply":"2023-11-01T13:05:02.388617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls my_pipeline/unet","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:02.391568Z","iopub.execute_input":"2023-11-01T13:05:02.391934Z","iopub.status.idle":"2023-11-01T13:05:03.420580Z","shell.execute_reply.started":"2023-11-01T13:05:02.391903Z","shell.execute_reply":"2023-11-01T13:05:03.419170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Option 2: Writing a Sampling Loop","metadata":{}},{"cell_type":"code","source":"sample = torch.randn(8, 3, 32, 32).to(device)\n\nfor i, t in enumerate(noise_scheduler.timesteps):\n    with torch.no_grad():\n        residual = model(sample, t).sample\n    sample = noise_scheduler.step(residual, t, sample).prev_sample\n\nshow_images(sample)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:03.422267Z","iopub.execute_input":"2023-11-01T13:05:03.422587Z","iopub.status.idle":"2023-11-01T13:05:24.546153Z","shell.execute_reply.started":"2023-11-01T13:05:03.422558Z","shell.execute_reply":"2023-11-01T13:05:24.545241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 7: Push your model to the Hub","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:27.491635Z","iopub.execute_input":"2023-11-01T13:05:27.491989Z","iopub.status.idle":"2023-11-01T13:05:27.514626Z","shell.execute_reply.started":"2023-11-01T13:05:27.491960Z","shell.execute_reply":"2023-11-01T13:05:27.513647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import get_full_repo_name\n\nmodel_name = 'sd-class-butterflies-32'\nhub_model_id = get_full_repo_name(model_name)\nhub_model_id","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:39.697402Z","iopub.execute_input":"2023-11-01T13:05:39.698288Z","iopub.status.idle":"2023-11-01T13:05:39.919684Z","shell.execute_reply.started":"2023-11-01T13:05:39.698251Z","shell.execute_reply":"2023-11-01T13:05:39.918672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfApi, create_repo\n\ncreate_repo(hub_model_id)\napi = HfApi()\napi.upload_folder(folder_path='my_pipeline/scheduler', path_in_repo='', repo_id=hub_model_id)\napi.upload_folder(folder_path='my_pipeline/unet', path_in_repo='', repo_id=hub_model_id)\napi.upload_file(\n    path_or_fileobj='my_pipeline/model_index.json',\n    path_in_repo='model_index.json',\n    repo_id=hub_model_id\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:40.117970Z","iopub.execute_input":"2023-11-01T13:05:40.118780Z","iopub.status.idle":"2023-11-01T13:05:41.975467Z","shell.execute_reply.started":"2023-11-01T13:05:40.118749Z","shell.execute_reply":"2023-11-01T13:05:41.974274Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import ModelCard\n\ncontent = f\"\"\"\n---\nlicense: mit\ntags:\n- pytorch\n- diffusers\n- unconditional-image-generation\n- diffusion-models-class\n---\n\n# Model Card for Unit 1 of the [Diffusion Models Class ðŸ§¨](https://github.com/huggingface/diffusion-models-class)\n\nThis model is a diffusion model for unconditional image generation of cute ðŸ¦‹.\n\n## Usage\n\n```python\nfrom diffusers import DDPMPipeline\n\npipeline = DDPMPipeline.from_pretrained('{hub_model_id}')\nimage = pipeline().images[0]\nimage\n```\n\"\"\"\n\ncard = ModelCard(content)\ncard.push_to_hub(hub_model_id)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:43:51.263885Z","iopub.execute_input":"2023-11-01T12:43:51.264298Z","iopub.status.idle":"2023-11-01T12:43:51.682358Z","shell.execute_reply.started":"2023-11-01T12:43:51.264266Z","shell.execute_reply":"2023-11-01T12:43:51.681436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from diffusers import DDPMPipeline\n\nimage_pipe = DDPMPipeline.from_pretrained(hub_model_id)\npipeline_output = image_pipe()\npipeline_output.images[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:44:52.674721Z","iopub.execute_input":"2023-11-01T12:44:52.675127Z","iopub.status.idle":"2023-11-01T12:45:52.432761Z","shell.execute_reply.started":"2023-11-01T12:44:52.675096Z","shell.execute_reply":"2023-11-01T12:45:52.431607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling up with HuggingFace Accelerate","metadata":{}},{"cell_type":"code","source":"!wget https://github.com/huggingface/diffusers/raw/main/examples/unconditional_image_generation/train_unconditional.py","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:45:52.434857Z","iopub.execute_input":"2023-11-01T12:45:52.435365Z","iopub.status.idle":"2023-11-01T12:45:53.955951Z","shell.execute_reply.started":"2023-11-01T12:45:52.435324Z","shell.execute_reply":"2023-11-01T12:45:53.954954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'sd-class-butterflies-64'\nhub_model_id = get_full_repo_name(model_name)\nhub_model_id","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:51:58.462005Z","iopub.execute_input":"2023-11-01T12:51:58.462701Z","iopub.status.idle":"2023-11-01T12:51:58.567149Z","shell.execute_reply.started":"2023-11-01T12:51:58.462662Z","shell.execute_reply":"2023-11-01T12:51:58.566197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!accelerate launch train_unconditional.py \\\n  --dataset_name=\"huggan/smithsonian_butterflies_subset\" \\\n  --resolution=64 \\\n  --output_dir={model_name} \\\n  --train_batch_size=32 \\\n  --num_epochs=50 \\\n  --gradient_accumulation_steps=1 \\\n  --learning_rate=1e-4 \\\n  --lr_warmup_steps=500 \\\n  --mixed_precision=\"no\"","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:50:46.603520Z","iopub.execute_input":"2023-11-01T12:50:46.603914Z","iopub.status.idle":"2023-11-01T12:50:56.292828Z","shell.execute_reply.started":"2023-11-01T12:50:46.603885Z","shell.execute_reply":"2023-11-01T12:50:56.291747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_repo(hub_model_id)\napi = HfApi()\napi.upload_folder(folder_path=f'{model_name}/scheduler', path_in_repo='', repo_id=hub_model_id)\napi.upload_folder(folder_path=f'{model_name}/unet', path_in_repo='', repo_id=hub_model_id)\napi.upload_file(\n    path_or_fileobj=f\"{model_name}/model_index.json\",\n    path_in_repo=\"model_index.json\",\n    repo_id=hub_model_id\n)\n\ncontent = f\"\"\"\n---\nlicense: mit\ntags:\n- pytorch\n- diffusers\n- unconditional-image-generation\n- diffusion-models-class\n---\n\n# Model Card for Unit 1 of the [Diffusion Models Class ðŸ§¨](https://github.com/huggingface/diffusion-models-class)\n\nThis model is a diffusion model for unconditional image generation of cute ðŸ¦‹.\n\n## Usage\n\n```python\nfrom diffusers import DDPMPipeline\n\npipeline = DDPMPipeline.from_pretrained('{hub_model_id}')\nimage = pipeline().images[0]\nimage\n```\n\"\"\"\n\ncard = ModelCard(content)\ncard.push_to_hub(hub_model_id)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:52:50.487016Z","iopub.execute_input":"2023-11-01T12:52:50.487424Z","iopub.status.idle":"2023-11-01T12:52:50.888719Z","shell.execute_reply.started":"2023-11-01T12:52:50.487392Z","shell.execute_reply":"2023-11-01T12:52:50.887402Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
